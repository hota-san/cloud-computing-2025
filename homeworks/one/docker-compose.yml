version: "3.8"

services:
  llm-inference:
    image: hotasan/llm-inference-image:latest  # Use your published Docker Hub image
    ports:
      - "8080:80"  # Map container port 80 to host 8080
    environment:
      METRICS_LOG_FILE: "/app/inside_compose_inference_metrics.csv"  # Set correct log file name
    volumes:
      - "./compose_inference_metrics.csv:/app/inside_compose_inference_metrics.csv"  # Map container file to host
